Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 36
Rules claiming more threads will be scaled down.
Job stats:
job            count    min threads    max threads
-----------  -------  -------------  -------------
all                1              1              1
getMetaData        1              1              1
total              2              1              1

Select jobs to execute...

[Mon May  8 11:05:07 2023]
rule getMetaData:
    input: /nfs/turbo/umms-indikar/shared/projects/wound_healing/data/sync-unsync/20230502-BJPF-sync-A3-20m.ome.tiff
    output: /scratch/indikar_root/indikar1/cstansbu/pf-test/metadata/test.json
    jobid: 2
    reason: Missing output files: /scratch/indikar_root/indikar1/cstansbu/pf-test/metadata/test.json
    resources: tmpdir=/tmp

[Mon May  8 11:05:09 2023]
Error in rule getMetaData:
    jobid: 2
    input: /nfs/turbo/umms-indikar/shared/projects/wound_healing/data/sync-unsync/20230502-BJPF-sync-A3-20m.ome.tiff
    output: /scratch/indikar_root/indikar1/cstansbu/pf-test/metadata/test.json
    shell:
        python scripts/getMetadata.py /nfs/turbo/umms-indikar/shared/projects/wound_healing/data/sync-unsync/20230502-BJPF-sync-A3-20m.ome.tiff /scratch/indikar_root/indikar1/cstansbu/pf-test/metadata/test.json
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2023-05-08T110505.819255.snakemake.log
